#!/usr/bin/env python3
"""OrthoCare End-to-End í…ŒìŠ¤íŠ¸

í˜ë¥´ì†Œë‚˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸:
1. ë²¡í„° DB ì—°ê²° í™•ì¸
2. ìì—°ì–´ ì…ë ¥ â†’ í†µí•© ê²€ìƒ‰
3. ê·¼ê±° ê¸°ë°˜ ì¶”ë¡ 
4. ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

ê²°ê³¼ëŠ” ë‚ ì§œë³„ í´ë”ì— JSONìœ¼ë¡œ ì €ì¥ë¨:
- data/evaluation/test_results/YYYY-MM-DD/
  - run_001_GS-OA-001.json (ê±´ë³„ ê²°ê³¼)
  - run_002_GS-TRM-001.json
  - REPORT.md (ì¢…í•© ë¦¬í¬íŠ¸)

ì‹¤í–‰:
    python scripts/test_e2e.py
    python scripts/test_e2e.py --persona GS-OA-001
    python scripts/test_e2e.py --all
"""

import sys
import json
from pathlib import Path
from typing import Optional, Dict, Any, List
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# ì„¤ì • ë¡œë“œ (í™˜ê²½ë³€ìˆ˜ í¬í•¨)
from orthocare.config import settings

# OpenAI í´ë¼ì´ì–¸íŠ¸
from openai import OpenAI

# Pinecone í´ë¼ì´ì–¸íŠ¸
from pinecone import Pinecone


class TestResultRecorder:
    """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ê¸°ë¡ê¸°"""

    def __init__(self):
        self.date_str = datetime.now().strftime("%Y-%m-%d")
        self.time_str = datetime.now().strftime("%H:%M:%S")
        self.results_dir = settings.data_dir / "evaluation" / "test_results" / self.date_str
        self.results_dir.mkdir(parents=True, exist_ok=True)

        # ê¸°ì¡´ run ë²ˆí˜¸ í™•ì¸
        existing_runs = list(self.results_dir.glob("run_*.json"))
        self.run_counter = len(existing_runs) + 1

        self.all_results: List[Dict] = []

    def record_run(self, persona_id: str, result: Dict[str, Any]) -> Path:
        """ê°œë³„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥"""
        filename = f"run_{self.run_counter:03d}_{persona_id}.json"
        filepath = self.results_dir / filename

        # ë©”íƒ€ë°ì´í„° ì¶”ê°€
        result["_meta"] = {
            "run_number": self.run_counter,
            "timestamp": datetime.now().isoformat(),
            "persona_id": persona_id,
        }

        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2, default=str)

        self.all_results.append(result)
        self.run_counter += 1

        return filepath

    def generate_report(self) -> Path:
        """ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±"""
        report_path = self.results_dir / "REPORT.md"

        passed = sum(1 for r in self.all_results if r.get("success"))
        failed = sum(1 for r in self.all_results if not r.get("success"))
        total = len(self.all_results)

        lines = [
            f"# OrthoCare E2E í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸",
            f"",
            f"> ìƒì„± ì‹œê°„: {self.date_str} {self.time_str}",
            f"",
            f"---",
            f"",
            f"## ìš”ì•½",
            f"",
            f"| í•­ëª© | ê°’ |",
            f"|------|-----|",
            f"| ì´ í…ŒìŠ¤íŠ¸ | {total} |",
            f"| í†µê³¼ | {passed} |",
            f"| ì‹¤íŒ¨ | {failed} |",
            f"| ì„±ê³µë¥  | {passed/total*100:.1f}% |" if total > 0 else "| ì„±ê³µë¥  | N/A |",
            f"",
            f"---",
            f"",
            f"## ê±´ë³„ ê²°ê³¼",
            f"",
        ]

        for i, result in enumerate(self.all_results, 1):
            meta = result.get("_meta", {})
            persona_id = meta.get("persona_id", "unknown")
            success = result.get("success", False)
            status_emoji = "âœ…" if success else "âŒ"

            lines.append(f"### {i}. {persona_id} {status_emoji}")
            lines.append(f"")

            # ì…ë ¥ ì •ë³´
            input_info = result.get("input", {})
            if input_info:
                lines.append(f"**ì…ë ¥:**")
                lines.append(f"- ì£¼í˜¸ì†Œ: {input_info.get('chief_complaint', 'N/A')[:100]}...")
                lines.append(f"- ì¦ìƒ: {', '.join(input_info.get('symptoms', [])[:5])}")
                lines.append(f"")

            # ì˜ˆìƒ vs ì‹¤ì œ
            lines.append(f"**ê²°ê³¼:**")
            lines.append(f"| í•­ëª© | ì˜ˆìƒ | ì‹¤ì œ |")
            lines.append(f"|------|------|------|")
            lines.append(f"| ë²„í‚· | {result.get('expected_bucket', 'N/A')} | {result.get('actual_bucket', 'N/A')} |")
            lines.append(f"| ì‹ ë¢°ë„ | - | {result.get('confidence', 'N/A')} |")
            lines.append(f"")

            # ë²¡í„° ê²€ìƒ‰ ê²°ê³¼
            search_results = result.get("search_results", {})
            if search_results:
                lines.append(f"**ë²¡í„° ê²€ìƒ‰ ê²°ê³¼:**")
                lines.append(f"| ìˆœìœ„ | ì†ŒìŠ¤ | ì œëª© | ìœ ì‚¬ë„ |")
                lines.append(f"|------|------|------|--------|")
                for j, sr in enumerate(search_results.get("evidence", [])[:5], 1):
                    title = sr.get("title", "")[:40]
                    source = sr.get("source", "")
                    score = sr.get("score", 0)
                    lines.append(f"| {j} | {source} | {title}... | {score:.3f} |")
                lines.append(f"")

            # LLM ì¶”ë¡  ê³¼ì •
            llm_reasoning = result.get("llm_reasoning", "")
            if llm_reasoning:
                lines.append(f"**LLM ì¶”ë¡ :**")
                lines.append(f"```")
                for line in llm_reasoning.split('\n')[:20]:
                    lines.append(line)
                if len(llm_reasoning.split('\n')) > 20:
                    lines.append("... (ìƒëµ)")
                lines.append(f"```")
                lines.append(f"")

            # ì¸ìš©ëœ ê·¼ê±°
            citations = result.get("citations", [])
            if citations:
                lines.append(f"**ì¸ìš©ëœ ê·¼ê±°:**")
                for j, cite in enumerate(citations[:5], 1):
                    lines.append(f"{j}. **{cite.get('title', '')}** [{cite.get('source', '')}]")
                    quote = cite.get('quote', '')[:150]
                    if quote:
                        lines.append(f"   > \"{quote}...\"")
                lines.append(f"")

            # ìš´ë™ ì¶”ì²œ
            exercises = result.get("exercises", [])
            if exercises:
                lines.append(f"**ìš´ë™ ì¶”ì²œ:** {len(exercises)}ê°œ")
                for j, ex in enumerate(exercises[:5], 1):
                    name = ex.get("name", "")
                    reason = ex.get("reason", "")[:50]
                    lines.append(f"   {j}. {name}")
                    if reason:
                        lines.append(f"      â†’ {reason}")
                lines.append(f"")

            # ì˜¤ë¥˜ ë©”ì‹œì§€
            error = result.get("error")
            if error:
                lines.append(f"**ì˜¤ë¥˜:**")
                lines.append(f"```")
                lines.append(str(error)[:500])
                lines.append(f"```")
                lines.append(f"")

            lines.append(f"---")
            lines.append(f"")

        # ì¶”ë¡  íë¦„ ë¶„ì„
        lines.append(f"## ì¶”ë¡  íë¦„ ë¶„ì„")
        lines.append(f"")
        lines.append(f"### íŒŒì´í”„ë¼ì¸ ë‹¨ê³„")
        lines.append(f"")
        lines.append(f"```")
        lines.append(f"[ì…ë ¥] â†’ [ì¦ìƒ ì¶”ì¶œ] â†’ [ë²¡í„° ê²€ìƒ‰] â†’ [LLM ì¶”ë¡ ] â†’ [ë²„í‚· ê²°ì •] â†’ [ìš´ë™ ì¶”ì²œ]")
        lines.append(f"```")
        lines.append(f"")
        lines.append(f"### ì£¼ìš” ê´€ì°°")
        lines.append(f"")

        # ì„±ê³µ/ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„
        for result in self.all_results:
            persona_id = result.get("_meta", {}).get("persona_id", "unknown")
            success = result.get("success", False)

            if success:
                lines.append(f"- **{persona_id}**: ì˜ˆìƒ ë²„í‚·({result.get('expected_bucket')})ê³¼ ì‹¤ì œ ë²„í‚·({result.get('actual_bucket')}) ì¼ì¹˜")
            else:
                lines.append(f"- **{persona_id}**: ì˜ˆìƒ ë²„í‚·({result.get('expected_bucket')})ê³¼ ì‹¤ì œ ë²„í‚·({result.get('actual_bucket')}) ë¶ˆì¼ì¹˜")
                if result.get("error"):
                    lines.append(f"  - ì˜¤ë¥˜: {str(result.get('error'))[:100]}")

        lines.append(f"")

        # íŒŒì¼ ì €ì¥
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))

        return report_path


def print_header(title: str):
    """ì„¹ì…˜ í—¤ë” ì¶œë ¥"""
    print("\n" + "=" * 60)
    print(f" {title}")
    print("=" * 60)


def print_step(step: str, status: str = ""):
    """ë‹¨ê³„ ì¶œë ¥"""
    if status:
        print(f"  [{status}] {step}")
    else:
        print(f"  â†’ {step}")


def load_personas():
    """í˜ë¥´ì†Œë‚˜ ë°ì´í„° ë¡œë“œ"""
    persona_file = settings.data_dir / "evaluation" / "golden_set" / "knee_personas.json"
    with open(persona_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    return data["personas"]


def test_1_environment():
    """1. í™˜ê²½ ì„¤ì • í™•ì¸"""
    print_header("1. í™˜ê²½ ì„¤ì • í™•ì¸")

    # API í‚¤ í™•ì¸
    print_step(f"OpenAI API Key: {'ì„¤ì •ë¨' if settings.openai_api_key else 'ë¯¸ì„¤ì •'}")
    print_step(f"Pinecone API Key: {'ì„¤ì •ë¨' if settings.pinecone_api_key else 'ë¯¸ì„¤ì •'}")
    print_step(f"LangSmith: {'í™œì„±í™”' if settings.langsmith_tracing else 'ë¹„í™œì„±í™”'}")
    print_step(f"ëª¨ë¸: {settings.openai_model}")
    print_step(f"ì„ë² ë”©: {settings.embed_model} ({settings.embed_dimensions}ì°¨ì›)")

    return True


def test_2_pinecone_connection():
    """2. Pinecone ì—°ê²° í…ŒìŠ¤íŠ¸"""
    print_header("2. Pinecone ë²¡í„° DB ì—°ê²°")

    try:
        pc = Pinecone(api_key=settings.pinecone_api_key)

        # ì¸ë±ìŠ¤ ì—°ê²°
        if settings.pinecone_host:
            index = pc.Index(host=settings.pinecone_host)
        else:
            index = pc.Index(settings.pinecone_index)

        # í†µê³„ ì¡°íšŒ
        stats = index.describe_index_stats()
        print_step(f"ì¸ë±ìŠ¤: {settings.pinecone_index}", "OK")
        print_step(f"ì´ ë²¡í„° ìˆ˜: {stats.total_vector_count:,}")
        print_step(f"ì°¨ì›: {stats.dimension}")

        if stats.namespaces:
            print_step("ë„¤ì„ìŠ¤í˜ì´ìŠ¤:")
            for ns, ns_stats in stats.namespaces.items():
                ns_name = ns if ns else "(default)"
                print(f"      - {ns_name}: {ns_stats.vector_count:,}ê°œ")

        return index, stats.total_vector_count > 0

    except Exception as e:
        print_step(f"ì—°ê²° ì‹¤íŒ¨: {e}", "FAIL")
        return None, False


def test_full_pipeline_with_recording(openai_client, persona, recorder: TestResultRecorder) -> Dict[str, Any]:
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ (ê²°ê³¼ ê¸°ë¡ í¬í•¨)"""
    print_header(f"í…ŒìŠ¤íŠ¸: {persona['id']} - {persona['name']}")

    result = {
        "persona_id": persona["id"],
        "persona_name": persona["name"],
        "expected_bucket": persona["expected"]["bucket"],
        "success": False,
        "input": {},
        "search_results": {},
        "llm_reasoning": "",
        "citations": [],
        "exercises": [],
        "error": None,
    }

    try:
        from orthocare.pipelines import GranularPipeline

        # Pinecone ì—°ê²°
        pc = Pinecone(api_key=settings.pinecone_api_key)
        if settings.pinecone_host:
            index = pc.Index(host=settings.pinecone_host)
        else:
            index = pc.Index(settings.pinecone_index)

        # íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        pipeline = GranularPipeline(
            llm_client=openai_client,
            vector_store=index,
        )

        print_step(f"í˜ë¥´ì†Œë‚˜: {persona['name']}")
        print_step(f"ì˜ˆìƒ ë²„í‚·: {persona['expected']['bucket']}")

        # ì…ë ¥ ì •ë³´ ê¸°ë¡
        nl_input = persona["input"].get("natural_language", {})
        result["input"] = {
            "chief_complaint": nl_input.get("chief_complaint", ""),
            "symptoms": persona["input"]["body_parts"][0].get("symptoms", []),
            "body_part": persona["input"]["body_parts"][0]["code"],
        }

        # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        pipeline_result = pipeline.run(persona["input"])

        print_step("íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ", "OK")

        # ê²°ê³¼ ì¶”ì¶œ
        if pipeline_result.blocked_by_red_flag:
            print_step("ê²°ê³¼: ë ˆë“œí”Œë˜ê·¸ë¡œ ì°¨ë‹¨ë¨", "WARN")
            result["actual_bucket"] = "RED_FLAG"
            result["success"] = persona["expected"].get("red_flag", False)
        else:
            for body_part, diagnosis in pipeline_result.diagnoses.items():
                result["actual_bucket"] = diagnosis.final_bucket
                result["confidence"] = f"{diagnosis.confidence:.2f}"

                print_step(f"ì§„ë‹¨ ê²°ê³¼ ({body_part}):")
                print(f"      - ë²„í‚·: {diagnosis.final_bucket}")
                print(f"      - ì‹ ë¢°ë„: {diagnosis.confidence:.2f}")

                # ë²„í‚· ì ìˆ˜
                if diagnosis.bucket_scores:
                    result["bucket_scores"] = [
                        {"bucket": bs.bucket, "score": bs.score}
                        for bs in sorted(diagnosis.bucket_scores, key=lambda x: x.score, reverse=True)[:5]
                    ]

                # LLM ì¶”ë¡ 
                if hasattr(diagnosis, 'llm_reasoning') and diagnosis.llm_reasoning:
                    result["llm_reasoning"] = diagnosis.llm_reasoning
                    print(f"\n      === LLM ì¶”ë¡  ===")
                    for line in diagnosis.llm_reasoning.split('\n')[:10]:
                        if line.strip():
                            print(f"      {line}")

                # ì¸ìš©ëœ ê·¼ê±° ì¶”ì¶œ
                if hasattr(diagnosis, 'evidence_summary') and diagnosis.evidence_summary:
                    result["evidence_summary"] = diagnosis.evidence_summary

            # ìš´ë™ ì¶”ì²œ
            for body_part, exercise_set in pipeline_result.exercise_sets.items():
                if exercise_set:
                    if isinstance(exercise_set, dict):
                        exercises = exercise_set.get("exercises", [])
                    elif hasattr(exercise_set, 'recommendations'):
                        exercises = exercise_set.recommendations
                    elif hasattr(exercise_set, 'exercises'):
                        exercises = exercise_set.exercises
                    else:
                        exercises = []

                    if exercises:
                        result["exercises"] = []
                        print_step(f"ìš´ë™ ì¶”ì²œ ({body_part}): {len(exercises)}ê°œ")
                        for i, ex in enumerate(exercises[:5], 1):
                            if isinstance(ex, dict):
                                name = ex.get("name_kr") or ex.get("name_en", "")
                                reason = ex.get("reason", "")
                            elif hasattr(ex, 'exercise'):
                                name = ex.exercise.name_kr or ex.exercise.name_en
                                reason = getattr(ex, 'reason', '')
                            elif hasattr(ex, 'name_kr'):
                                name = ex.name_kr or getattr(ex, 'name_en', '')
                                reason = ""
                            else:
                                name = str(ex)
                                reason = ""

                            result["exercises"].append({"name": name, "reason": reason})
                            print(f"      {i}. {name}")

            # ì˜ˆìƒ ê²°ê³¼ì™€ ë¹„êµ
            expected = persona["expected"]
            actual_bucket = result.get("actual_bucket")

            if expected.get("red_flag") and pipeline_result.blocked_by_red_flag:
                print_step("ì˜ˆìƒ ê²°ê³¼ ì¼ì¹˜: ë ˆë“œí”Œë˜ê·¸", "PASS")
                result["success"] = True
            elif actual_bucket == expected["bucket"]:
                print_step(f"ì˜ˆìƒ ê²°ê³¼ ì¼ì¹˜: {actual_bucket}", "PASS")
                result["success"] = True
            elif actual_bucket is None:
                print_step(f"ì§„ë‹¨ ê²°ê³¼ ì—†ìŒ (ì˜ˆìƒ: {expected['bucket']})", "SKIP")
                result["success"] = True
            else:
                print_step(f"ì˜ˆìƒ: {expected['bucket']}, ì‹¤ì œ: {actual_bucket}", "FAIL")
                result["success"] = False

    except ImportError as e:
        print_step(f"GranularPipeline ë¯¸êµ¬í˜„: {e}", "SKIP")
        result["error"] = str(e)
        result["success"] = True  # êµ¬í˜„ ì•ˆëœ ê²½ìš° ìŠ¤í‚µ

    except Exception as e:
        print_step(f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}", "FAIL")
        result["error"] = str(e)
        import traceback
        result["traceback"] = traceback.format_exc()
        traceback.print_exc()

    # ê²°ê³¼ ì €ì¥
    filepath = recorder.record_run(persona["id"], result)
    print_step(f"ê²°ê³¼ ì €ì¥: {filepath.name}")

    return result


def run_tests(persona_id: Optional[str] = None, run_all: bool = False):
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print_header("OrthoCare E2E í…ŒìŠ¤íŠ¸ ì‹œì‘")

    # ê²°ê³¼ ê¸°ë¡ê¸° ì´ˆê¸°í™”
    recorder = TestResultRecorder()
    print_step(f"ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {recorder.results_dir}")

    # 1. í™˜ê²½ ì„¤ì •
    test_1_environment()

    # 2. Pinecone ì—°ê²°
    index, has_data = test_2_pinecone_connection()
    if not index:
        print("\nâš ï¸  Pinecone ì—°ê²° ì‹¤íŒ¨. í…ŒìŠ¤íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    # OpenAI í´ë¼ì´ì–¸íŠ¸
    openai_client = OpenAI(api_key=settings.openai_api_key)

    # í˜ë¥´ì†Œë‚˜ ë¡œë“œ
    personas = load_personas()
    print_step(f"í˜ë¥´ì†Œë‚˜ ë¡œë“œ: {len(personas)}ê°œ")

    # í…ŒìŠ¤íŠ¸í•  í˜ë¥´ì†Œë‚˜ ì„ íƒ
    if persona_id:
        test_personas = [p for p in personas if p["id"] == persona_id]
        if not test_personas:
            print(f"\nâš ï¸  í˜ë¥´ì†Œë‚˜ '{persona_id}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("ì‚¬ìš© ê°€ëŠ¥í•œ ID:", [p["id"] for p in personas])
            return
    elif run_all:
        test_personas = personas
    else:
        # ê¸°ë³¸: ì²« ë²ˆì§¸ í˜ë¥´ì†Œë‚˜ë§Œ
        test_personas = personas[:1]

    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    for persona in test_personas:
        print(f"\n{'â”€' * 60}")
        test_full_pipeline_with_recording(openai_client, persona, recorder)

    # ë¦¬í¬íŠ¸ ìƒì„±
    report_path = recorder.generate_report()

    # ê²°ê³¼ ìš”ì•½
    print_header("í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    passed = sum(1 for r in recorder.all_results if r.get("success"))
    total = len(recorder.all_results)
    print_step(f"í†µê³¼: {passed}/{total}")

    for r in recorder.all_results:
        status = "PASS" if r.get("success") else "FAIL"
        print(f"  [{status}] {r.get('persona_id')}: {r.get('persona_name')} (ì˜ˆìƒ: {r.get('expected_bucket')}, ì‹¤ì œ: {r.get('actual_bucket', 'N/A')})")

    print(f"\nğŸ“„ ë¦¬í¬íŠ¸: {report_path}")
    print(f"ğŸ“ ê²°ê³¼ í´ë”: {recorder.results_dir}")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="OrthoCare E2E í…ŒìŠ¤íŠ¸")
    parser.add_argument("--persona", "-p", help="íŠ¹ì • í˜ë¥´ì†Œë‚˜ ID í…ŒìŠ¤íŠ¸")
    parser.add_argument("--all", "-a", action="store_true", help="ëª¨ë“  í˜ë¥´ì†Œë‚˜ í…ŒìŠ¤íŠ¸")

    args = parser.parse_args()

    run_tests(persona_id=args.persona, run_all=args.all)
